{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T16:08:19.833174Z",
     "start_time": "2022-06-27T16:07:52.106386Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPIV = np.load()\n",
    "model = torch.load(\"path/to/ckpt/file\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eweights0= model['state_dict']['encoder.0.weight']\n",
    "Ebias0= model['state_dict']['encoder.0.bias']\n",
    "Eweights0g = np.asarray(Eweights0)\n",
    "Ebias0g = np.asarray(Ebias0)\n",
    "\n",
    "Eweights2= model['state_dict']['encoder.3.weight']\n",
    "Ebias2= model['state_dict']['encoder.3.bias']\n",
    "Eweights3 = np.asarray(Eweights2)\n",
    "Ebias3 = np.asarray(Ebias2)\n",
    "\n",
    "Eweights0= model['state_dict']['encoder.6.weight']\n",
    "Ebias0= model['state_dict']['encoder.6.bias']\n",
    "Eweights6 = np.asarray(Eweights0)\n",
    "Ebias6 = np.asarray(Ebias0)\n",
    "\n",
    "Eweights2= model['state_dict']['encoder.9.weight']\n",
    "Ebias2= model['state_dict']['encoder.9.bias']\n",
    "Eweights9 = np.asarray(Eweights2)\n",
    "Ebias9 = np.asarray(Ebias2)\n",
    "\n",
    "weights2= np.asarray(model['state_dict']['encoder.2.weight'])\n",
    "bias2= np.asarray(model['state_dict']['encoder.2.bias'])\n",
    "mu2= np.asarray(model['state_dict']['encoder.2.running_mean'])\n",
    "var2= np.sqrt(np.asarray(model['state_dict']['encoder.2.running_var']) + 0.00001)\n",
    "\n",
    "weights5= np.asarray(model['state_dict']['encoder.5.weight'])\n",
    "bias5= np.asarray(model['state_dict']['encoder.5.bias'])\n",
    "mu5= np.asarray(model['state_dict']['encoder.5.running_mean'])\n",
    "var5= np.sqrt(np.asarray(model['state_dict']['encoder.5.running_var']) + 0.00001)\n",
    "\n",
    "weights8= np.asarray(model['state_dict']['encoder.8.weight'])\n",
    "bias8= np.asarray(model['state_dict']['encoder.8.bias'])\n",
    "mu8= np.asarray(model['state_dict']['encoder.8.running_mean'])\n",
    "var8= np.sqrt(np.asarray(model['state_dict']['encoder.8.running_var']) + 0.00001)\n",
    "\n",
    "weights11= np.asarray(model['state_dict']['encoder.11.weight'])\n",
    "bias11= np.asarray(model['state_dict']['encoder.11.bias'])\n",
    "mu11= np.asarray(model['state_dict']['encoder.11.running_mean'])\n",
    "var11= np.sqrt(np.asarray(model['state_dict']['encoder.11.running_var']) + 0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "E_H1 = ((np.tanh(np.dot(inputPIV,Eweights0g.T) + Ebias0g) - mu2)/var2)*weights2 + bias2\n",
    "E_H2 = ((np.tanh(np.dot(E_H1,Eweights3.T) + Ebias3) - mu5)/var5)*weights5 + bias5\n",
    "E_H3 = ((np.tanh(np.dot(E_H2,Eweights6.T) + Ebias6) - mu8)/var8)*weights8 + bias8\n",
    "Latent = ((np.tanh(np.dot(E_H3,Eweights9.T) + Ebias9) - mu11)/var11)*weights11 + bias11\n",
    "pcaLatent = np.dot(Latent,pca_comps.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
